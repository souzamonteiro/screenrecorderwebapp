<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="theme-color" content="#1a2a6c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="mobile-web-app-capable" content="yes">
    <title>Screen Recorder</title>
    <link rel="icon" href="icons/favicon.ico" type="image/x-icon">
    <link rel="manifest" href="manifest.json">
    <link rel="apple-touch-icon" href="icons/icon-152x152.png">

    <!-- CSS Libraries -->
    <link rel="stylesheet" href="css/fontawesome.min.css">
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        body {
            background: linear-gradient(135deg, #1a2a6c, #b21f1f, #fdbb2d);
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            background-color: rgba(255, 255, 255, 0.9);
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
            width: 480px;
            max-width: calc(100% - 40px);
            overflow: hidden;
            padding: 30px;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 20px;
            font-weight: 600;
        }

        .button-container {
            display: flex;
            justify-content: space-between;
            gap: 15px;
            margin-bottom: 20px;
        }

        button {
            flex: 1;
            padding: 15px;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-weight: bold;
            font-size: 16px;
            transition: all 0.3s ease;
            color: white;
        }

        #record {
            background-color: #2a9d8f;
        }

        #pause {
            background-color: #264653;
        }

        #stop {
            background-color: #e63946;
        }

        #save {
            background-color: #f4a261;
        }

        button:hover {
            transform: translateY(-3px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }

        button:active {
            transform: translateY(-1px);
        }

        #status {
            text-align: center;
            margin-top: 20px;
            padding: 10px;
            border-radius: 8px;
            font-weight: 500;
        }

        .recording {
            background-color: #ff7b7b;
        }

        .paused {
            background-color: #ffeaa7;
        }

        .saved {
            background-color: #a2ff98;
        }

        .preview {
            margin-top: 20px;
            width: 100%;
            height: 200px;
            background-color: #000; /* letterbox background */
            border-radius: 8px;
            overflow: hidden;
            position: relative;
            display: none;
        }

        .preview video {
            width: 100%;
            height: 100%;
            object-fit: contain; /* üîë keeps aspect ratio */
            background-color: #000;
        }

        .file-info {
            margin-top: 15px;
            text-align: center;
            font-size: 14px;
            color: #555;
        }

        .file-info button {
            margin-top: 10px;
            padding: 8px 15px;
            background-color: #457b9d;
            border-radius: 4px;
        }

        .hidden {
            display: none;
        }

        /* Audio controls layout improvements */
        .audio-controls {
            display: flex;
            gap: 8px;
            align-items: center;
            flex-wrap: wrap;
        }

        .audio-controls label {
            flex: 0 0 auto;
            margin-right: 6px;
            white-space: nowrap;
        }

        .audio-controls select {
            flex: 1 1 160px;
            min-width: 140px;
            max-width: 100%;
            padding: 8px;
            border-radius: 6px;
        }

        #mic-devices {
            flex: 2 1 220px;
            min-width: 180px;
        }

        .checkbox-container {
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .checkbox-container input[type="checkbox"] {
            width: 18px;
            height: 18px;
            cursor: pointer;
        }

        .checkbox-container label {
            margin: 0;
            cursor: pointer;
            flex: 1;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Screen Recorder</h1>
        <div class="button-container">
            <button id="record">Record</button>
            <button id="pause" disabled>Pause</button>
            <button id="stop" disabled>Stop</button>
        </div>
        <div class="audio-controls" style="margin:12px 0; display:flex; gap:8px; align-items:center;">
            <label for="audio-source" style="font-size:14px; color:#333;">Audio:</label>
            <select id="audio-source" style="flex:1; padding:8px; border-radius:6px;">
                <option value="microphone">Microphone only</option>
                <option value="system">System/Tab audio only</option>
                <option value="mic+system">Microphone + System</option>
            </select>
            <select id="mic-devices" class="hidden" style="padding:8px; border-radius:6px;"></select>
        </div>
        <div style="margin:12px 0; display:flex; gap:8px; align-items:center;">
            <div class="checkbox-container" style="margin: 0;">
                <input type="checkbox" id="rnnoise-toggle">
                <label for="rnnoise-toggle" style="font-size:14px; color:#333; margin-bottom: 0;">Enable Noise Filtering (RNNoise)</label>
            </div>
        </div>
        <div id="status">Click Record to start</div>
        <div class="preview">
            <video id="preview" class="hidden"></video>
        </div>
        <div class="file-info hidden" id="file-info">
            <p>Recording saved as <span id="file-name"></span></p>
        </div>

        <div style="margin-top: 40px; padding: 20px; text-align: center; color: var(--dark-gray); font-size: 14px; border-top: 1px solid #e0e0e0;">
            <p style="margin-bottom: 10px;">
                &copy; 2026 Roberto Luiz Souza Monteiro. All rights reserved.
            </p>
            <p style="margin-bottom: 10px;">
                <a href="https://github.com/souzamonteiro/screenrecorderwebapp.git" 
                    target="_blank"
                    style="color: var(--primary-color); text-decoration: none; display: inline-flex; align-items: center; gap: 6px;"
                    onmouseover="this.style.textDecoration='underline'"
                    onmouseout="this.style.textDecoration='none'">
                    <i class="fa-brands fa-github"></i>
                    View source code on GitHub
                </a>
            </p>
            <p style="font-size: 12px; opacity: 0.8;">
                This project is licensed under the Apache 2.0 License.
            </p>
        </div>
    </div>

    <script type="module">
        // Import the RNNoise module and initialize with correct wasm location
        import rnnoise from './libs/rnnoise.js';

        try {
            // Pass locateFile so the loader finds rnnoise.wasm inside ./libs/
            const RNNoiseModule = await rnnoise({ locateFile: path => './libs/' + path });
            window.RNNoiseModule = RNNoiseModule;
            console.log('‚úÖ RNNoise module initialized');
            console.log('Available functions:', {
                create: !!RNNoiseModule._rnnoise_create,
                destroy: !!RNNoiseModule._rnnoise_destroy,
                process: !!RNNoiseModule._rnnoise_process_frame,
                malloc: !!RNNoiseModule._malloc,
                free: !!RNNoiseModule._free
            });
        } catch (err) {
            console.error('‚ùå Failed to initialize RNNoise module:', err);
        }
    </script>

    <script>
        // DOM elements
        const recordButton = document.getElementById('record');
        const pauseButton = document.getElementById('pause');
        const stopButton = document.getElementById('stop');
        const statusDiv = document.getElementById('status');
        const previewVideo = document.getElementById('preview');
        const previewContainer = document.querySelector('.preview'); // Added this line
        const fileInfoDiv = document.getElementById('file-info');
        const fileNameSpan = document.getElementById('file-name');
        const audioSourceSelect = document.getElementById('audio-source');
        const micDevicesSelect = document.getElementById('mic-devices');
        const rnnoiseToggle = document.getElementById('rnnoise-toggle');

        // Global variables
        let recordedChunks = [];
        let mediaRecorder = null;
        let stream = null;
        let micStream = null;
        let displayStreamRef = null;
        let audioCtx = null;
        let audioDestination = null;
        let recordingStartTime = 0;
        let recordingDuration = 0;
        let rnnoiseProcessor = null;
        let scriptNode = null;
        let currentMicSource = null;
        let isFilterEnabled = false;

        // Setup RNNoise processor for noise reduction - FIXED VERSION
        async function setupRNNoiseProcessor(sourceNode, destinationNode) {
            console.log('üîß Setting up RNNoise processor...');
            
            try {
                // Check if RNNoise module is available
                if (typeof window.RNNoiseModule === 'undefined') {
                    console.warn('RNNoise module not loaded yet');
                    await new Promise(resolve => setTimeout(resolve, 500));
                    if (typeof window.RNNoiseModule === 'undefined') {
                        console.warn('RNNoise module still not available');
                        return false;
                    }
                }

                const RNNoiseModule = window.RNNoiseModule;
                
                // Wait for module to be ready
                if (typeof RNNoiseModule.ready !== 'undefined') {
                    await RNNoiseModule.ready;
                }

                // Create RNNoise state - LIKE IN C CODE
                let denoiserState = null;
                try {
                    // First, clean up any existing state
                    if (rnnoiseProcessor && rnnoiseProcessor.state) {
                        try {
                            if (RNNoiseModule._rnnoise_destroy) {
                                RNNoiseModule._rnnoise_destroy(rnnoiseProcessor.state);
                            }
                        } catch(e) {}
                    }
                    
                    // Free WASM buffers if they exist
                    if (rnnoiseProcessor && rnnoiseProcessor.pcmInputBuf) {
                        try { RNNoiseModule._free(rnnoiseProcessor.pcmInputBuf); } catch(e){}
                    }
                    if (rnnoiseProcessor && rnnoiseProcessor.pcmOutputBuf) {
                        try { RNNoiseModule._free(rnnoiseProcessor.pcmOutputBuf); } catch(e){}
                    }
                    
                    // Create new state - LIKE C CODE: state->rnnoise_state = rnnoise_create(NULL);
                    if (RNNoiseModule._rnnoise_create) {
                        denoiserState = RNNoiseModule._rnnoise_create();
                        console.log('‚úÖ RNNoise state created');
                    } else {
                        console.warn('‚ùå RNNoise create function not found');
                        return false;
                    }
                } catch (err) {
                    console.warn('Error creating RNNoise state:', err);
                    return false;
                }

                // Create ScriptProcessorNode
                const bufferSize = 512;
                scriptNode = audioCtx.createScriptProcessor(bufferSize, 1, 1);

                // Constants - SAME AS C CODE
                const FRAME_SIZE = 480; // RNNOISE_FRAME_SIZE in C code
                const heap = RNNoiseModule;
                
                // Allocate WASM buffers - SAME SIZE AS C CODE EXPECTS
                const BUFFER_BYTE_SIZE = FRAME_SIZE * 4; // Float32 = 4 bytes
                const pcmInputBuf = heap._malloc(BUFFER_BYTE_SIZE);
                const pcmOutputBuf = heap._malloc(BUFFER_BYTE_SIZE);
                
                if (!pcmInputBuf || !pcmOutputBuf) {
                    console.warn('Failed to allocate WASM buffers');
                    return false;
                }
                
                const pcmInputIndex = pcmInputBuf >> 2;
                const pcmOutputIndex = pcmOutputBuf >> 2;

                // Store for cleanup
                rnnoiseProcessor = { 
                    state: denoiserState, 
                    module: RNNoiseModule, 
                    pcmInputBuf, 
                    pcmOutputBuf 
                };

                // Processing state - SIMILAR TO C CODE
                let accBuf = new Float32Array(FRAME_SIZE);
                let accLen = 0;
                let processedQueue = [];
                let warmupFrames = 2; // Like C code: static bool first_frame = true;
                let framesProcessed = 0;

                // Audio processing callback - FIXED VERSION
                scriptNode.onaudioprocess = (event) => {
                    const input = event.inputBuffer.getChannelData(0);
                    const output = event.outputBuffer.getChannelData(0);

                    let inPos = 0;

                    try {
                        while (inPos < input.length) {
                            const need = FRAME_SIZE - accLen;
                            const take = Math.min(need, input.length - inPos);
                            
                            // Accumulate samples
                            accBuf.set(input.subarray(inPos, inPos + take), accLen);
                            accLen += take;
                            inPos += take;

                            if (accLen === FRAME_SIZE) {
                                // CRITICAL FIX: Convert audio data to match C code
                                // C code: float_buffer[j] = (float)(l + r / 2);
                                // This converts int16 stereo to float mono
                                
                                const toSend = new Float32Array(FRAME_SIZE);
                                
                                // IMPORTANT: Web Audio API gives us float32 in range [-1, 1]
                                // RNNoise expects float32 with int16 range [-32768, 32767]
                                // So we need to scale like the C code does
                                for (let t = 0; t < FRAME_SIZE; t++) {
                                    toSend[t] = accBuf[t] * 32768.0; // Scale to int16 range
                                }
                                
                                // Copy to WASM memory
                                heap.HEAPF32.set(toSend, pcmInputIndex);

                                // Process frame - LIKE C CODE: rnnoise_process_frame(state->rnnoise_state, output_buffer, float_buffer);
                                heap._rnnoise_process_frame(denoiserState, pcmOutputBuf, pcmInputBuf);

                                // Get processed data
                                const processed = new Float32Array(FRAME_SIZE);
                                processed.set(heap.HEAPF32.subarray(pcmOutputIndex, pcmOutputIndex + FRAME_SIZE));

                                // Apply clipping and scaling back - LIKE C CODE
                                const RNNOISE_GAIN = 0.95; // Same as C demo
                                for (let k = 0; k < processed.length; k++) {
                                    let s = processed[k] * RNNOISE_GAIN / 32768.0; // Scale back to [-1, 1]
                                    if (s > 1.0) s = 1.0;
                                    else if (s < -1.0) s = -1.0;
                                    processed[k] = s;
                                }

                                // Skip first frames for warm-up - LIKE C CODE
                                framesProcessed++;
                                if (framesProcessed > warmupFrames) {
                                    processedQueue.push(processed);
                                } else {
                                    // During warm-up, pass through original audio (not silence)
                                    processedQueue.push(accBuf.slice());
                                }
                                
                                accLen = 0;
                            }
                        }
                    } catch (err) {
                        console.warn('Error in RNNoise processing:', err);
                        accLen = 0;
                        processedQueue.length = 0;
                    }

                    // Fill output buffer
                    let outPos = 0;
                    while (outPos < output.length) {
                        if (processedQueue.length > 0) {
                            const blk = processedQueue[0];
                            const take = Math.min(blk.length, output.length - outPos);
                            output.set(blk.subarray(0, take), outPos);
                            
                            if (take < blk.length) {
                                processedQueue[0] = blk.subarray(take);
                            } else {
                                processedQueue.shift();
                            }
                            outPos += take;
                        } else {
                            // No processed data - output silence temporarily
                            for (let i = outPos; i < output.length; i++) {
                                output[i] = 0;
                            }
                            break;
                        }
                    }
                };

                // Connect nodes
                sourceNode.disconnect();
                sourceNode.connect(scriptNode);
                scriptNode.connect(destinationNode);
                
                isFilterEnabled = true;
                console.log('‚úÖ RNNoise processor setup complete');
                return true;
                
            } catch (error) {
                console.error('‚ùå Failed to setup RNNoise:', error);
                return false;
            }
        }

        // Disable RNNoise filter and connect audio directly
        function disableRNNoiseFilter() {
            console.log('üîß Disabling RNNoise filter...');
            
            try {
                if (currentMicSource && audioDestination) {
                    // Disconnect everything
                    if (scriptNode) {
                        try {
                            scriptNode.disconnect();
                        } catch(e) {}
                        scriptNode = null;
                    }
                    
                    // Clean up RNNoise state
                    if (rnnoiseProcessor && rnnoiseProcessor.state) {
                        try {
                            if (rnnoiseProcessor.module && rnnoiseProcessor.module._rnnoise_destroy) {
                                rnnoiseProcessor.module._rnnoise_destroy(rnnoiseProcessor.state);
                            }
                        } catch(e) {}
                        rnnoiseProcessor.state = null;
                    }
                    
                    // Connect directly
                    currentMicSource.disconnect();
                    currentMicSource.connect(audioDestination);
                    
                    isFilterEnabled = false;
                    console.log('‚úÖ RNNoise filter disabled');
                    return true;
                }
            } catch (error) {
                console.error('Error disabling filter:', error);
            }
            return false;
        }

        // Toggle filter during recording
        async function toggleFilterDuringRecording(enable) {
            if (!currentMicSource || !audioDestination) {
                console.warn('No active audio source for filter toggle');
                return false;
            }
            
            const wasRecording = mediaRecorder && mediaRecorder.state === 'recording';
            
            try {
                if (wasRecording) {
                    mediaRecorder.pause();
                    await new Promise(resolve => setTimeout(resolve, 50));
                }
                
                if (enable) {
                    await setupRNNoiseProcessor(currentMicSource, audioDestination);
                } else {
                    disableRNNoiseFilter();
                }
                
                if (wasRecording) {
                    await new Promise(resolve => setTimeout(resolve, 50));
                    mediaRecorder.resume();
                }
                
                statusDiv.textContent = `Recording... (Noise filter ${enable ? 'enabled' : 'disabled'})`;
                return true;
                
            } catch (error) {
                console.error('Error toggling filter:', error);
                return false;
            }
        }

        // Populate microphone devices
        async function populateMicDevices() {
            try {
                let devices = await navigator.mediaDevices.enumerateDevices();
                let mics = devices.filter(d => d.kind === 'audioinput');

                const haveLabels = mics.some(m => m.label && m.label.trim() !== '');
                if (!haveLabels) {
                    try {
                        const tempStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                        tempStream.getTracks().forEach(t => t.stop());
                        devices = await navigator.mediaDevices.enumerateDevices();
                        mics = devices.filter(d => d.kind === 'audioinput');
                    } catch (permErr) {
                        console.warn('Microphone permission not granted:', permErr);
                    }
                }

                micDevicesSelect.innerHTML = '';
                mics.forEach(mic => {
                    const opt = document.createElement('option');
                    opt.value = mic.deviceId;
                    opt.textContent = mic.label && mic.label.trim() !== '' ? 
                        mic.label : `Microphone (${mic.deviceId ? mic.deviceId.slice(0,6) : 'unknown'})`;
                    micDevicesSelect.appendChild(opt);
                });
                
                micDevicesSelect.classList.toggle('hidden', mics.length === 0);
            } catch (err) {
                console.warn('Could not enumerate devices:', err);
            }
        }

        // Get user media (screen, audio)
        async function getScreenStream() {
            try {
                const audioChoice = audioSourceSelect.value;
                const needsSystem = (audioChoice === 'system' || audioChoice === 'mic+system');
                const needsMic = (audioChoice === 'microphone' || audioChoice === 'mic+system');

                // Request display stream
                const displayStream = await navigator.mediaDevices.getDisplayMedia({
                    video: { cursor: "always" },
                    audio: needsSystem
                });

                // Get microphone if requested
                micStream = null;
                if (needsMic) {
                    try {
                        const micConstraint = {};
                        if (micDevicesSelect.value) {
                            micConstraint.deviceId = { exact: micDevicesSelect.value };
                        }
                        micStream = await navigator.mediaDevices.getUserMedia({ audio: micConstraint });
                    } catch (err) {
                        console.warn('Microphone not available:', err);
                    }
                }

                displayStreamRef = displayStream;
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                audioDestination = audioCtx.createMediaStreamDestination();

                // Connect system audio if needed
                if (needsSystem && displayStream.getAudioTracks().length > 0) {
                    try {
                        const displayAudioSrc = audioCtx.createMediaStreamSource(
                            new MediaStream(displayStream.getAudioTracks())
                        );
                        displayAudioSrc.connect(audioDestination);
                    } catch (err) {
                        console.warn('Could not connect system audio:', err);
                    }
                }

                // Connect microphone with optional RNNoise filter
                if (micStream && micStream.getAudioTracks().length > 0) {
                    try {
                        currentMicSource = audioCtx.createMediaStreamSource(
                            new MediaStream(micStream.getAudioTracks())
                        );
                        
                        if (rnnoiseToggle.checked) {
                            const success = await setupRNNoiseProcessor(currentMicSource, audioDestination);
                            if (!success) {
                                console.warn('RNNoise failed, using direct connection');
                                currentMicSource.connect(audioDestination);
                            }
                        } else {
                            currentMicSource.connect(audioDestination);
                        }
                    } catch (err) {
                        console.warn('Could not connect microphone:', err);
                    }
                }

                // Create final stream
                const combinedTracks = [
                    ...displayStream.getVideoTracks(),
                    ...audioDestination.stream.getAudioTracks()
                ];
                stream = new MediaStream(combinedTracks);

                // Setup media recorder
                mediaRecorder = new MediaRecorder(stream, { 
                    mimeType: 'video/webm;codecs=vp9', 
                    audioBitsPerSecond: 128000 
                });
                
                mediaRecorder.ondataavailable = handleDataAvailable;
                mediaRecorder.onstop = handleStop;
                mediaRecorder.start();

                // Update status
                if (needsMic && micStream) {
                    statusDiv.textContent = `Recording... (Microphone, Filter ${rnnoiseToggle.checked ? 'ON' : 'OFF'})`;
                } else if (needsSystem) {
                    statusDiv.textContent = 'Recording... (System audio)';
                } else {
                    statusDiv.textContent = 'Recording... (No audio)';
                }

                // FIXED PREVIEW: Show the container and video
                previewContainer.style.display = 'block'; // This was missing!
                previewVideo.srcObject = stream;
                previewVideo.muted = true;
                previewVideo.classList.remove('hidden');
                previewVideo.play().catch(err => console.log('Preview autoplay prevented:', err));
                
                // Update UI
                recordButton.disabled = true;
                pauseButton.disabled = false;
                stopButton.disabled = false;
                statusDiv.classList.add('recording');
                recordingStartTime = Date.now();
                
            } catch (error) {
                console.error('Error accessing screen:', error);
                statusDiv.textContent = 'Error accessing screen. Please try again.';
            }
        }

        // Handle data available from media recorder
        function handleDataAvailable(event) {
            if (event.data.size > 0) {
                recordedChunks.push(event.data);
            }
        }

        // Stop recording
        function handleStop() {
            // FIXED: Hide preview when stopping
            previewContainer.style.display = 'none';
            previewVideo.srcObject = null;
            previewVideo.classList.add('hidden');
            
            // Stop all tracks
            if (stream) stream.getTracks().forEach(track => track.stop());
            if (micStream) micStream.getTracks().forEach(track => track.stop());
            if (displayStreamRef) displayStreamRef.getTracks().forEach(track => track.stop());
            
            // Clean up RNNoise
            if (rnnoiseProcessor) {
                try {
                    if (rnnoiseProcessor.module && rnnoiseProcessor.module._rnnoise_destroy && rnnoiseProcessor.state) {
                        rnnoiseProcessor.module._rnnoise_destroy(rnnoiseProcessor.state);
                    }
                } catch(e){}
                rnnoiseProcessor = null;
            }
            
            // Clean up audio nodes
            if (scriptNode) {
                try { scriptNode.disconnect(); } catch(e){}
                scriptNode = null;
            }
            
            if (audioCtx) {
                try { audioCtx.close(); } catch(e){}
                audioCtx = null;
                audioDestination = null;
            }
            
            currentMicSource = null;
            isFilterEnabled = false;
            
            // Create and save file
            if (recordedChunks.length > 0) {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const file = new File([blob], `recording-${new Date().toISOString().slice(0, 19)}.webm`);
                const url = URL.createObjectURL(blob);
                
                fileNameSpan.textContent = file.name;
                fileInfoDiv.classList.remove('hidden');
                
                const a = document.createElement('a');
                a.href = url;
                a.download = file.name;
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            }
            
            // Reset UI
            recordButton.disabled = false;
            pauseButton.disabled = true;
            stopButton.disabled = true;
            statusDiv.textContent = 'Recording saved!';
            statusDiv.classList.remove('recording', 'paused');
            statusDiv.classList.add('saved');
            pauseButton.textContent = 'Pause';
            recordedChunks = [];
        }

        // Pause recording
        function pauseRecording() {
            if (!mediaRecorder) return;

            if (mediaRecorder.state === 'recording') {
                recordingDuration += Date.now() - recordingStartTime;
                mediaRecorder.pause();
                statusDiv.textContent = 'Recording paused';
                statusDiv.classList.remove('recording');
                statusDiv.classList.add('paused');
                pauseButton.textContent = 'Resume';
            } else if (mediaRecorder.state === 'paused') {
                recordingStartTime = Date.now();
                mediaRecorder.resume();
                statusDiv.textContent = 'Recording...';
                statusDiv.classList.remove('paused');
                statusDiv.classList.add('recording');
                pauseButton.textContent = 'Pause';
            }
        }

        // Event listeners
        recordButton.addEventListener('click', async () => {
            try {
                await getScreenStream();
            } catch (error) {
                console.error('Error starting recording:', error);
                statusDiv.textContent = 'Error starting recording. Please try again.';
            }
        });

        audioSourceSelect.addEventListener('change', async () => {
            const val = audioSourceSelect.value;
            if (val === 'microphone' || val === 'mic+system') {
                await populateMicDevices();
                micDevicesSelect.classList.remove('hidden');
            } else {
                micDevicesSelect.classList.add('hidden');
            }
        });

        pauseButton.addEventListener('click', pauseRecording);

        stopButton.addEventListener('click', () => {
            if (mediaRecorder && (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused')) {
                mediaRecorder.stop();
            }
        });

        // Toggle filter during recording
        rnnoiseToggle.addEventListener('change', async () => {
            if (currentMicSource && audioDestination) {
                const enabled = rnnoiseToggle.checked;
                console.log(`üéöÔ∏è Toggling noise filter: ${enabled ? 'ON' : 'OFF'}`);
                
                if (mediaRecorder && (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused')) {
                    await toggleFilterDuringRecording(enabled);
                } else {
                    // Update status for next recording
                    statusDiv.textContent = `Filter will be ${enabled ? 'enabled' : 'disabled'} on next recording`;
                }
            }
        });

        // Initial population
        populateMicDevices();

        // Clean up on page unload
        window.addEventListener('beforeunload', () => {
            if (stream) stream.getTracks().forEach(track => track.stop());
            if (rnnoiseProcessor && rnnoiseProcessor.state) {
                try {
                    if (rnnoiseProcessor.module && rnnoiseProcessor.module._rnnoise_destroy) {
                        rnnoiseProcessor.module._rnnoise_destroy(rnnoiseProcessor.state);
                    }
                } catch(e){}
            }
            if (scriptNode) {
                try { scriptNode.disconnect(); } catch(e){}
            }
            if (audioCtx) {
                try { audioCtx.close(); } catch(e){}
            }
        });
    </script>

    <script>
        if ('serviceWorker' in navigator) {
            navigator.serviceWorker.register('./sw.js')
            .then(() => console.log('Service Worker successfully registered.'))
            .catch(err => console.error('Erro SW:', err));
        }
    </script>
</body>
</html>
